{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"stackoverflow_question_langauges_classificator.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMIDpDXTFdxOw+fUXVPCm0C"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"nR4NVMFJud0P","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598430702522,"user_tz":-120,"elapsed":2228,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["import matplotlib.pyplot as plt\n","import os\n","import re\n","import shutil\n","import string \n","import tensorflow as tf\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import losses\n","from tensorflow.keras import preprocessing\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"WTHx6K_KuBZi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598430707704,"user_tz":-120,"elapsed":668,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["url = 'http://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"6v3Gd1OFucf3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598430719464,"user_tz":-120,"elapsed":4636,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"d751db7e-0071-4f9d-9332-373601714195"},"source":["dataset = tf.keras.utils.get_file('stack_overflow_16k.tar.gz', url, untar=True, cache_dir='.', cache_subdir='.')\n","dataset_dir = os.path.join(os.path.dirname(dataset), 'stack_overflow')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz\n","6053888/6053168 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p5NfHLR13jZY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598430910228,"user_tz":-120,"elapsed":601,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["sample_file = os.path.join('train/', 'python/1500.txt')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKHE5y5J58vQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1598430931761,"user_tz":-120,"elapsed":691,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"e82acde6-8c02-493d-e1f6-5f7b53fbdb28"},"source":["with open(sample_file) as f:\n","  print(f.read())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["\"using blank to encapsulate part of a string after 3 commas i am trying to create a blank script that adds quotations around part of a string, after 3 commas..so if the input data looks like this:..1234,1,1/1/2010,this is a test. one, two, three....i want blank to convert the string to:..1234,1,1/1/2010,\"\"this is a test. one, two, three.\"\"...the quotes will always need to be added after 3 commas..i am using blank 3.1.2 and have the following so far:..i_file=open(\"\"input.csv\"\",\"\"r\"\").o_file=open(\"\"output.csv\"\",\"\"w\"\")..for line in i_file:.        tokens=line.split(\"\",\"\").        count=0.        new_line=\"\"\"\".        for element in tokens:.                if count = \"\"3\"\":.                        new_line = new_line + '\"\"' + element + '\"\"'.                        break.                else:.                        new_line = new_line + element + \"\",\"\".                        count=count+1..        o_file.write(new_line + \"\"n\"\").        print(line, \"\" -&gt; \"\", new_line)..i_file.close().o_file.close()...the script closes immediately when i try to run it and produces no output..can you see what's wrong?..thanks\"\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c-AXwVnQ6GhS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598430965923,"user_tz":-120,"elapsed":636,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"ea53acfd-495e-4c3d-da78-832b3d605125"},"source":["ls train/"],"execution_count":10,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mcsharp\u001b[0m/  \u001b[01;34mjava\u001b[0m/  \u001b[01;34mjavascript\u001b[0m/  \u001b[01;34mpython\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tea_Htn76O2Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598431088112,"user_tz":-120,"elapsed":1182,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"07ea2033-7b33-4100-ab0a-bf971b123bd6"},"source":["batch_size = 32\n","seed = 42\n","\n","raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory('train/',\n","                                                                  batch_size=batch_size,\n","                                                                  seed=seed,\n","                                                                  validation_split=0.2,\n","                                                                  subset='training')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Found 8000 files belonging to 4 classes.\n","Using 6400 files for training.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"157ceE8t6ska","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1598431467100,"user_tz":-120,"elapsed":647,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"e9e55ab4-4589-442f-96be-a14899e24e37"},"source":["for text_batch, label_batch in raw_train_ds.take(1):\n","  for i in range(3):\n","    print('Question: ', text_batch.numpy()[i])\n","    print('Label: ', label_batch.numpy()[i])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Question:  b'\"blank8 why is my solution faster than the neat solution? (hackerrank chocolate feast) edit: simplified my solution..edit: removed opinion based secondary question...background: atarted learning blank a week or two ago using hackerranks problems as exercises and stackoverflow search + google as my teacher, i\\'ve had some limited experience learning other languages...i did the exercise my own \"\"noobish learner way\"\" which i can\\'t help but feel is a \"\"botched job\"\" when i see \"\"neat &amp; short\"\" solutions...however, when submitting both solutions one after another a couple of times i found the \"\"neat\"\" solution was quite a bit slower. ..i vaguely remember something about % operations being costly, is mine faster because of no % operations or is there more to it than just that?..exercise: https://www.hackerrank.com/challenges/chocolate-feast..neat solution from discussion:..import blank.io.*;.import blank.util.*;..public class solution {.    static int cc; .    public static void main(string[] args) {.        scanner in = new scanner(system.in);.        int t,n,c,m,r;.            t = in.nextint();.            while(t--&gt;0){.             n = in.nextint();.            c = in.nextint();.             m = in.nextint();.                r=n/c;.                cc=r;..                    while(r&gt;=m){.                        cc=cc+r/m;.                        r=r%m+r/m;.                    }..                system.out.println(cc); .            }..    }.}...my solution:..import blank.io.*;.import blank.util.*;..public class solution {..    public static void main(string[] args) {..        scanner sc = new scanner(system.in);.        int t = integer.parseint(sc.nextline());    //t = number of test cases.        int[][] tc = readinput(sc, t);              //tc[t][0] = money. tc[t][1] = price. tc[t][2] = wrappers per free bar..        for (int i = 0; i&lt;t; i++){                  //loop for all test cases.            int choc = calcchoc(tc,i);              //work out how much choc can be bought.            system.out.println(choc);               //print result for the test case.        }.    }.    //calculate how much choc he can buy with m $ at p price with w wrappers needed for a free bar.    public static int calcchoc(int[][] tc,int i){..        int m = tc[i][0];       //money he has.        int p = tc[i][1];       //price of choc.        int w = tc[i][2];       //wrappers per free bar..        int bars = m/p;         //how many bars he can buy initially.        int wrappers = bars;    //each bar is a wrapper from initial purpose..        //loop to turn in all wrappers while it is possible to do so.        while (w&lt;=wrappers){..            int barsfromturnin = wrappers/w;                //bars from turning in current wrappers..            bars = bars + barsfromturnin;                   //new bar count.            wrappers = wrappers - (barsfromturnin * (w-1)); //wrapper count reduced by amount of wrappers turned in -1 wrapper per bar recieved from turn in...            if (w==1){ //break out of infinite loop when you get 1 bar for 1 wrapper!.                system.out.print(\"\"infinite bars, exiting infinite loop at bars = \"\");.                break;.            }.        }.        return bars;.    }.    //read input for each test case and make 2d array of the info.    public static int[][] readinput(scanner sc, int t){..        int[][] input = new int[t][3];..        for (int i = 0; i&lt;t; i++){.            string[] inputline = sc.nextline().split(\"\" \"\");..            input[i][0] = integer.parseint(inputline[0]);.            input[i][1] = integer.parseint(inputline[1]);.            input[i][2] = integer.parseint(inputline[2]);.        }.        return input;.    }.}\"\\n'\n","Label:  1\n","Question:  b'\"element.removeeventlistener(\\'mousedown\\', externalfunction, usecapture); is not working i need to first remove the event listener before dynamically adding more elements which also need the same event listener. i am using an external function name (not an anonymous function) and specifying the same usecapture value in both the add and remove. ..the function is nested within another function. &lt; suspected problem was the problem..you can see the problem by clicking the first \"\"add button\"\"  more than once. the first click adds one more button, the second click adds two more, the third click adds four more, etc. each click should only add one more. i guess the return value of removeeventlistener is always undefined so i can only tell that removal did not work from the duplicate events.....var app = function() {. console.log(\\'app\\');. . var setup = function() {.  console.log(\\'setup\\');. .  var addbutton = function(e) {.   console.log(e);.   var button = e.target;.   var newbutton = document.createelement(\\'button\\');.   newbutton.innertext = \\'add another button\\';.   button.parentnode.appendchild( newbutton );.   setup();.  }. .  var buttons = document.queryselectorall(\\'button\\');.  .  for(var i=0; i&lt;buttons.length; i++) {.   var button = buttons[i];.   button.removeeventlistener(\\'mousedown\\', addbutton, false);.   button.addeventlistener(\\'mousedown\\', addbutton, false);.  }.  . }. setup();.}.app();.&lt;div&gt;. &lt;button&gt;add button&lt;/button&gt;.&lt;/div&gt;\"\\n'\n","Label:  2\n","Question:  b'\"downloading a file using blank i have some code to download a text file from a website. when the requested file does not exist, my application downloads a text file which has html content. i need to filter this html content (should not download a text file with html content if the requested file does not exist) and need to download only text files which has the correct content. below is my code...string filepath = @\"\"c:textfiles\"\" + filename + string.format(\"\"{0:00000}\"\", i) + \"\".txt\"\";.directory.createdirectory(path.getdirectoryname(filepath));.//messagebox.show(filepath);..using (filestream download = new filestream(filepath, filemode.create)).{.    stream stream = clientx.getresponse().getresponsestream();.    while ((read = stream.read(buffer, 0, buffer.length)) != 0).    {..        download.write(buffer, 0, read);..    }.}...please advice\"\\n'\n","Label:  0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LoSIrtVq7FkM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1598431576646,"user_tz":-120,"elapsed":701,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"071307d2-013b-4456-f159-6982e5a15381"},"source":["for i in range(4):\n","  print(f'Label {i} corresponds to {raw_train_ds.class_names[i]}')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Label 0 corresponds to csharp\n","Label 1 corresponds to java\n","Label 2 corresponds to javascript\n","Label 3 corresponds to python\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QuksSYV58jAG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598431868533,"user_tz":-120,"elapsed":695,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"78b3bf19-f5e2-49bd-e58c-f33ef053da5c"},"source":["raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory('train/',\n","                                                                  batch_size=batch_size,\n","                                                                  seed=seed,\n","                                                                  validation_split=0.2,\n","                                                                  subset='validation')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Found 8000 files belonging to 4 classes.\n","Using 1600 files for validation.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pM0D8MH9BkgH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598432923273,"user_tz":-120,"elapsed":919,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"8b09fd9f-afb8-4138-e38d-8de85cddf21c"},"source":["raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory('test/',\n","                                                                 batch_size=batch_size)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Found 8000 files belonging to 4 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LQmFlYzt9rOE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598432171589,"user_tz":-120,"elapsed":581,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["def custom_standarization(input_data):\n","  lowercase = tf.strings.lower(input_data)\n","  return tf.strings.regex_replace(lowercase, '[%s]' % re.escape(string.punctuation), ' ')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"g4gUhbsQ9vaf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598432311172,"user_tz":-120,"elapsed":738,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["max_features = 10000\n","sequence_length = 250\n","\n","vectorize_layer = TextVectorization(standardize=custom_standarization,\n","                                    max_tokens = max_features,\n","                                    output_mode = 'int',\n","                                    output_sequence_length = sequence_length)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtu-6vg7_XRb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598432415781,"user_tz":-120,"elapsed":3234,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["train_text = raw_train_ds.map(lambda x, y:x)\n","vectorize_layer.adapt(train_text)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mw_-KBEd_wNZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598432483008,"user_tz":-120,"elapsed":601,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["def vectorize_text(text, label):\n","  text = tf.expand_dims(text, -1)\n","  return vectorize_layer(text), label"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"07CqPHezABQ9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":479},"executionInfo":{"status":"ok","timestamp":1598432647941,"user_tz":-120,"elapsed":619,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"2a64178b-3727-4d2b-a19c-0dc687f0091e"},"source":["text_batch, label_batch = next(iter(raw_train_ds))\n","first_text, first_label = text_batch[0], label_batch[0]\n","print('first question ', first_text)\n","print('first label ', first_label)\n","print('vectorized question ', vectorize_text(first_text, first_label))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["first question  tf.Tensor(b'\"set blank to quit on exception? i\\'m using blank 3..i\\'ve been looking around for an answer to this, but i haven\\'t found it yet. basically, i\\'m running several blank scripts into a game engine, and each script has its own entry point...i\\'d rather not add try: except blocks through all of my code, so i was wondering if it\\'s at all possible to tell blank to quit (or perhaps assign a custom function to that \"\"callback\"\") on finding its first error, regardless of where or what it found? ..currently, the game engine will continue after finding and hitting an error, making it more difficult than necessary to diagnose issues since running into one error may make a subsequent script not work (as it relies on variables that the error-ing script set, for example). any ideas? ..i know that i could redirect the console to a file to allow for easier scrolling, but just capturing the first error and stopping the game prematurely would be really useful...okay, a couple of extra bits of info - sorry for neglecting to say this. the engine i\\'m using (the blender game engine) is coded in c, so changing the source is more than i\\'d like to do.....after googling, it would appear that a similar question with a solid answer has been asked here, which is how to get the last raised exception. if i check the sys module for the presence of the last_value variable and it exists, then i can quit prematurely, as the console would have already printed out the error...thanks for the help.\"\\n', shape=(), dtype=string)\n","first label  tf.Tensor(3, shape=(), dtype=int32)\n","vectorized question  (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n","array([[ 126,   17,    4, 1150,   54,  220,    2,   57,   58,   17,   53,\n","           2,  241,  308,  612,  711,   18,   48,  229,    4,   12,   31,\n","           2, 2105,   47,  289,   16, 1106,  745,    2,   57,  439, 1001,\n","          17, 1314,  146,    5,  303, 1719,   10,  167,  133,  140,  271,\n","         879,  791,  363,    2,  120, 1078,   36,   73,  153,  666, 2745,\n","         281,  100,   13,   28,   29,   64,    2,  165,  796,   14,   16,\n","          46,   81,  100,  278,    4,  597,   17,    4, 1150,   65, 2096,\n","         758,    5,  896,   32,    4,   21,  904,   54, 1322,  271,  125,\n","          75, 3253,   13,  171,   65,   62,   16,  289,  542,    3,  303,\n","        1719,  110,  673,  209, 1322,   10, 8550,   48,   75,  663,   16,\n","         250, 3184,  282, 1889,    4,    1, 1493,  628,  439,  146,   94,\n","          75,  642,  143,    5, 4533,  133,   36,  169,   51,   16,    1,\n","          54,  323,   21,    3,   75,    1,  133,  126,   18,  132,  102,\n","         886,    2,  151,   21,    2,  246, 2199,    3,   85,    4,    5,\n","          37,    4, 1008,   18, 1851, 4124,   31,  152,    1,    3,  125,\n","          75,   10, 3754,    3,  303,    1,  101,   50,  518, 2194, 2128,\n","           5, 2413,   13, 1498, 3200,   13,  441,  797,   18,    1,    4,\n","         449,   12,    3, 1719,    2,   57,   58,    3,    1,  303, 1719,\n","           7, 2999,    9,   79,   64, 1058,    3,  337,    7,  250,  282,\n","           2,  120,   66,    4,   55,  209, 5308,   16,  101, 1165,   21,\n","           5,  696,  184,   34,    5, 2151,  229,  140,  308, 1268,   98,\n","          96,    7,   30,    4,   45,    3,  270, 3944,  220,   14,    2,\n","         224,    3,  508,  324,   18,    3,    1,   13]])>, <tf.Tensor: shape=(), dtype=int32, numpy=3>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GwKZWBUpAphu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598432732498,"user_tz":-120,"elapsed":602,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"40659829-365b-4711-c01f-9fb228f1f9e7"},"source":["print('17 ----> ', vectorize_layer.get_vocabulary()[17] )"],"execution_count":26,"outputs":[{"output_type":"stream","text":["17 ---->  blank\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t3-GzXJjA-LP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598432927458,"user_tz":-120,"elapsed":648,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["train_ds = raw_train_ds.map(vectorize_text)\n","test_ds = raw_test_ds.map(vectorize_text)\n","val_ds = raw_val_ds.map(vectorize_text)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNZPiCR7BXOX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598433166421,"user_tz":-120,"elapsed":564,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","train_ds = train_ds.cache().prefetch(buffer_size = AUTOTUNE)\n","test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"rjExelnXCoHV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598433658392,"user_tz":-120,"elapsed":617,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["embedding_size = 16\n","\n","model = tf.keras.Sequential([layers.Embedding(max_features+1, embedding_size),\n","                            layers.Dropout(0.2),\n","                            layers.GlobalAveragePooling1D(),\n","                            layers.Dropout(0.2),\n","                            layers.Dense(4)])"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"ciwRrIY-Cq8t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"executionInfo":{"status":"ok","timestamp":1598433659574,"user_tz":-120,"elapsed":635,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"4ab27ce3-c35f-4d65-ebd9-4df71d7bce33"},"source":["model.summary()"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, None, 16)          160016    \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, None, 16)          0         \n","_________________________________________________________________\n","global_average_pooling1d_2 ( (None, 16)                0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 16)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4)                 68        \n","=================================================================\n","Total params: 160,084\n","Trainable params: 160,084\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ToIDfBctDKS5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598433661080,"user_tz":-120,"elapsed":624,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["model.compile(optimizer='adam', loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"N996Q5ToDi-0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598433720932,"user_tz":-120,"elapsed":610,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}}},"source":["epochs = 100"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"yoMLZGz5Dkjt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598433842216,"user_tz":-120,"elapsed":121361,"user":{"displayName":"Jakub Kaminiarz","photoUrl":"","userId":"17300534047414142009"}},"outputId":"6f1b4e94-8b52-4436-e653-299b49bd2e09"},"source":["history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.5841 - binary_accuracy: 0.2734 - val_loss: 0.6108 - val_binary_accuracy: 0.2672\n","Epoch 2/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.5472 - binary_accuracy: 0.2728 - val_loss: 0.5836 - val_binary_accuracy: 0.2663\n","Epoch 3/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.5159 - binary_accuracy: 0.2744 - val_loss: 0.5594 - val_binary_accuracy: 0.2663\n","Epoch 4/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.4859 - binary_accuracy: 0.2727 - val_loss: 0.5390 - val_binary_accuracy: 0.2648\n","Epoch 5/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.4629 - binary_accuracy: 0.2732 - val_loss: 0.5207 - val_binary_accuracy: 0.2652\n","Epoch 6/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.4411 - binary_accuracy: 0.2707 - val_loss: 0.5048 - val_binary_accuracy: 0.2639\n","Epoch 7/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.4190 - binary_accuracy: 0.2711 - val_loss: 0.4909 - val_binary_accuracy: 0.2647\n","Epoch 8/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.4016 - binary_accuracy: 0.2707 - val_loss: 0.4780 - val_binary_accuracy: 0.2637\n","Epoch 9/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.3830 - binary_accuracy: 0.2708 - val_loss: 0.4666 - val_binary_accuracy: 0.2633\n","Epoch 10/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.3681 - binary_accuracy: 0.2714 - val_loss: 0.4560 - val_binary_accuracy: 0.2625\n","Epoch 11/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.3499 - binary_accuracy: 0.2698 - val_loss: 0.4466 - val_binary_accuracy: 0.2623\n","Epoch 12/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.3366 - binary_accuracy: 0.2697 - val_loss: 0.4384 - val_binary_accuracy: 0.2606\n","Epoch 13/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.3235 - binary_accuracy: 0.2696 - val_loss: 0.4309 - val_binary_accuracy: 0.2611\n","Epoch 14/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.3092 - binary_accuracy: 0.2699 - val_loss: 0.4236 - val_binary_accuracy: 0.2598\n","Epoch 15/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.2987 - binary_accuracy: 0.2691 - val_loss: 0.4171 - val_binary_accuracy: 0.2605\n","Epoch 16/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.2886 - binary_accuracy: 0.2688 - val_loss: 0.4120 - val_binary_accuracy: 0.2609\n","Epoch 17/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.2755 - binary_accuracy: 0.2670 - val_loss: 0.4063 - val_binary_accuracy: 0.2594\n","Epoch 18/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.2655 - binary_accuracy: 0.2687 - val_loss: 0.4016 - val_binary_accuracy: 0.2594\n","Epoch 19/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.2544 - binary_accuracy: 0.2685 - val_loss: 0.3972 - val_binary_accuracy: 0.2581\n","Epoch 20/100\n","200/200 [==============================] - 1s 7ms/step - loss: 0.2457 - binary_accuracy: 0.2672 - val_loss: 0.3937 - val_binary_accuracy: 0.2572\n","Epoch 21/100\n","200/200 [==============================] - 1s 7ms/step - loss: 0.2377 - binary_accuracy: 0.2686 - val_loss: 0.3905 - val_binary_accuracy: 0.2573\n","Epoch 22/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.2294 - binary_accuracy: 0.2668 - val_loss: 0.3876 - val_binary_accuracy: 0.2578\n","Epoch 23/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.2211 - binary_accuracy: 0.2677 - val_loss: 0.3844 - val_binary_accuracy: 0.2567\n","Epoch 24/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.2156 - binary_accuracy: 0.2681 - val_loss: 0.3820 - val_binary_accuracy: 0.2559\n","Epoch 25/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.2057 - binary_accuracy: 0.2659 - val_loss: 0.3801 - val_binary_accuracy: 0.2559\n","Epoch 26/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1990 - binary_accuracy: 0.2668 - val_loss: 0.3789 - val_binary_accuracy: 0.2558\n","Epoch 27/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1926 - binary_accuracy: 0.2684 - val_loss: 0.3776 - val_binary_accuracy: 0.2555\n","Epoch 28/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1863 - binary_accuracy: 0.2675 - val_loss: 0.3766 - val_binary_accuracy: 0.2561\n","Epoch 29/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1794 - binary_accuracy: 0.2653 - val_loss: 0.3752 - val_binary_accuracy: 0.2561\n","Epoch 30/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1730 - binary_accuracy: 0.2673 - val_loss: 0.3745 - val_binary_accuracy: 0.2561\n","Epoch 31/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1698 - binary_accuracy: 0.2664 - val_loss: 0.3746 - val_binary_accuracy: 0.2553\n","Epoch 32/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1614 - binary_accuracy: 0.2673 - val_loss: 0.3739 - val_binary_accuracy: 0.2555\n","Epoch 33/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1576 - binary_accuracy: 0.2661 - val_loss: 0.3729 - val_binary_accuracy: 0.2547\n","Epoch 34/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1514 - binary_accuracy: 0.2667 - val_loss: 0.3737 - val_binary_accuracy: 0.2553\n","Epoch 35/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1481 - binary_accuracy: 0.2637 - val_loss: 0.3740 - val_binary_accuracy: 0.2550\n","Epoch 36/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1418 - binary_accuracy: 0.2678 - val_loss: 0.3749 - val_binary_accuracy: 0.2550\n","Epoch 37/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1377 - binary_accuracy: 0.2657 - val_loss: 0.3742 - val_binary_accuracy: 0.2539\n","Epoch 38/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1331 - binary_accuracy: 0.2640 - val_loss: 0.3748 - val_binary_accuracy: 0.2536\n","Epoch 39/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1281 - binary_accuracy: 0.2646 - val_loss: 0.3756 - val_binary_accuracy: 0.2544\n","Epoch 40/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1246 - binary_accuracy: 0.2653 - val_loss: 0.3761 - val_binary_accuracy: 0.2523\n","Epoch 41/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1220 - binary_accuracy: 0.2657 - val_loss: 0.3777 - val_binary_accuracy: 0.2523\n","Epoch 42/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1156 - binary_accuracy: 0.2644 - val_loss: 0.3789 - val_binary_accuracy: 0.2533\n","Epoch 43/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1116 - binary_accuracy: 0.2659 - val_loss: 0.3805 - val_binary_accuracy: 0.2525\n","Epoch 44/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1094 - binary_accuracy: 0.2652 - val_loss: 0.3820 - val_binary_accuracy: 0.2523\n","Epoch 45/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1065 - binary_accuracy: 0.2639 - val_loss: 0.3847 - val_binary_accuracy: 0.2511\n","Epoch 46/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.1010 - binary_accuracy: 0.2641 - val_loss: 0.3864 - val_binary_accuracy: 0.2512\n","Epoch 47/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0975 - binary_accuracy: 0.2637 - val_loss: 0.3880 - val_binary_accuracy: 0.2511\n","Epoch 48/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0955 - binary_accuracy: 0.2656 - val_loss: 0.3905 - val_binary_accuracy: 0.2500\n","Epoch 49/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0926 - binary_accuracy: 0.2637 - val_loss: 0.3921 - val_binary_accuracy: 0.2492\n","Epoch 50/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0884 - binary_accuracy: 0.2627 - val_loss: 0.3948 - val_binary_accuracy: 0.2495\n","Epoch 51/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0865 - binary_accuracy: 0.2647 - val_loss: 0.3983 - val_binary_accuracy: 0.2502\n","Epoch 52/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0859 - binary_accuracy: 0.2625 - val_loss: 0.4003 - val_binary_accuracy: 0.2483\n","Epoch 53/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0806 - binary_accuracy: 0.2642 - val_loss: 0.4025 - val_binary_accuracy: 0.2484\n","Epoch 54/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0787 - binary_accuracy: 0.2627 - val_loss: 0.4060 - val_binary_accuracy: 0.2492\n","Epoch 55/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0757 - binary_accuracy: 0.2620 - val_loss: 0.4078 - val_binary_accuracy: 0.2488\n","Epoch 56/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0740 - binary_accuracy: 0.2641 - val_loss: 0.4110 - val_binary_accuracy: 0.2480\n","Epoch 57/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0714 - binary_accuracy: 0.2637 - val_loss: 0.4140 - val_binary_accuracy: 0.2475\n","Epoch 58/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0669 - binary_accuracy: 0.2629 - val_loss: 0.4167 - val_binary_accuracy: 0.2469\n","Epoch 59/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0648 - binary_accuracy: 0.2629 - val_loss: 0.4214 - val_binary_accuracy: 0.2467\n","Epoch 60/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0638 - binary_accuracy: 0.2616 - val_loss: 0.4234 - val_binary_accuracy: 0.2470\n","Epoch 61/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0614 - binary_accuracy: 0.2611 - val_loss: 0.4266 - val_binary_accuracy: 0.2466\n","Epoch 62/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0611 - binary_accuracy: 0.2615 - val_loss: 0.4307 - val_binary_accuracy: 0.2472\n","Epoch 63/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0566 - binary_accuracy: 0.2632 - val_loss: 0.4336 - val_binary_accuracy: 0.2472\n","Epoch 64/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0567 - binary_accuracy: 0.2612 - val_loss: 0.4371 - val_binary_accuracy: 0.2478\n","Epoch 65/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0540 - binary_accuracy: 0.2638 - val_loss: 0.4410 - val_binary_accuracy: 0.2473\n","Epoch 66/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0513 - binary_accuracy: 0.2621 - val_loss: 0.4445 - val_binary_accuracy: 0.2483\n","Epoch 67/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0508 - binary_accuracy: 0.2629 - val_loss: 0.4485 - val_binary_accuracy: 0.2478\n","Epoch 68/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0489 - binary_accuracy: 0.2621 - val_loss: 0.4519 - val_binary_accuracy: 0.2488\n","Epoch 69/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0476 - binary_accuracy: 0.2622 - val_loss: 0.4560 - val_binary_accuracy: 0.2483\n","Epoch 70/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0471 - binary_accuracy: 0.2621 - val_loss: 0.4603 - val_binary_accuracy: 0.2481\n","Epoch 71/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0455 - binary_accuracy: 0.2612 - val_loss: 0.4633 - val_binary_accuracy: 0.2475\n","Epoch 72/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0419 - binary_accuracy: 0.2611 - val_loss: 0.4678 - val_binary_accuracy: 0.2477\n","Epoch 73/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0424 - binary_accuracy: 0.2619 - val_loss: 0.4710 - val_binary_accuracy: 0.2467\n","Epoch 74/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0415 - binary_accuracy: 0.2616 - val_loss: 0.4761 - val_binary_accuracy: 0.2483\n","Epoch 75/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0389 - binary_accuracy: 0.2615 - val_loss: 0.4807 - val_binary_accuracy: 0.2478\n","Epoch 76/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0386 - binary_accuracy: 0.2605 - val_loss: 0.4851 - val_binary_accuracy: 0.2481\n","Epoch 77/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0373 - binary_accuracy: 0.2632 - val_loss: 0.4878 - val_binary_accuracy: 0.2472\n","Epoch 78/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0344 - binary_accuracy: 0.2618 - val_loss: 0.4934 - val_binary_accuracy: 0.2472\n","Epoch 79/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0340 - binary_accuracy: 0.2597 - val_loss: 0.4971 - val_binary_accuracy: 0.2470\n","Epoch 80/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0330 - binary_accuracy: 0.2605 - val_loss: 0.5018 - val_binary_accuracy: 0.2477\n","Epoch 81/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0327 - binary_accuracy: 0.2604 - val_loss: 0.5060 - val_binary_accuracy: 0.2469\n","Epoch 82/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0314 - binary_accuracy: 0.2608 - val_loss: 0.5086 - val_binary_accuracy: 0.2472\n","Epoch 83/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0300 - binary_accuracy: 0.2602 - val_loss: 0.5131 - val_binary_accuracy: 0.2463\n","Epoch 84/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0289 - binary_accuracy: 0.2597 - val_loss: 0.5171 - val_binary_accuracy: 0.2463\n","Epoch 85/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0297 - binary_accuracy: 0.2588 - val_loss: 0.5201 - val_binary_accuracy: 0.2461\n","Epoch 86/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0277 - binary_accuracy: 0.2607 - val_loss: 0.5254 - val_binary_accuracy: 0.2459\n","Epoch 87/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0265 - binary_accuracy: 0.2607 - val_loss: 0.5295 - val_binary_accuracy: 0.2467\n","Epoch 88/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0262 - binary_accuracy: 0.2612 - val_loss: 0.5335 - val_binary_accuracy: 0.2470\n","Epoch 89/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0252 - binary_accuracy: 0.2599 - val_loss: 0.5366 - val_binary_accuracy: 0.2459\n","Epoch 90/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0246 - binary_accuracy: 0.2605 - val_loss: 0.5445 - val_binary_accuracy: 0.2480\n","Epoch 91/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0236 - binary_accuracy: 0.2600 - val_loss: 0.5465 - val_binary_accuracy: 0.2461\n","Epoch 92/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0231 - binary_accuracy: 0.2616 - val_loss: 0.5519 - val_binary_accuracy: 0.2461\n","Epoch 93/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0222 - binary_accuracy: 0.2598 - val_loss: 0.5563 - val_binary_accuracy: 0.2469\n","Epoch 94/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0219 - binary_accuracy: 0.2601 - val_loss: 0.5620 - val_binary_accuracy: 0.2469\n","Epoch 95/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0219 - binary_accuracy: 0.2605 - val_loss: 0.5698 - val_binary_accuracy: 0.2486\n","Epoch 96/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0202 - binary_accuracy: 0.2605 - val_loss: 0.5740 - val_binary_accuracy: 0.2475\n","Epoch 97/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0188 - binary_accuracy: 0.2616 - val_loss: 0.5786 - val_binary_accuracy: 0.2475\n","Epoch 98/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0181 - binary_accuracy: 0.2623 - val_loss: 0.5831 - val_binary_accuracy: 0.2475\n","Epoch 99/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0188 - binary_accuracy: 0.2608 - val_loss: 0.5878 - val_binary_accuracy: 0.2470\n","Epoch 100/100\n","200/200 [==============================] - 1s 6ms/step - loss: 0.0174 - binary_accuracy: 0.2611 - val_loss: 0.5921 - val_binary_accuracy: 0.2475\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nwdkBC5ADunb","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}